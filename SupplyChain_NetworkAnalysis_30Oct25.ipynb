{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1o6-iTPNXIqI_m4vJE_cOFCpa692Hw_Yj",
      "authorship_tag": "ABX9TyPdk+SbS1iwYGwvVdjBwZye",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silveira-alysson/supply-network-analysis/blob/main/SupplyChain_NetworkAnalysis_30Oct25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Alysson Silveira**\n",
        "**10-Aug-2025**\n",
        "## My Procedure to Clean Up the Revere–FactSet Supply Chain Dataset\n",
        "\n",
        "## Data Cleaning and Construction Steps\n",
        "\n",
        "1. **Add GVKEY to the dyad dataset**  \n",
        "   This step is performed early because multiple `source_company_id` and `target_company_id` values can map to a single CUSIP (e.g., subsidiaries).  \n",
        "   Adding GVKEY at this stage allows aggregation across all company IDs under the same GVKEY, avoiding duplication.\n",
        "\n",
        "2. **Extract year variables**  \n",
        "   Extracted `start_year` and `end_year` from the start and end date fields.\n",
        "\n",
        "3. **Handle missing end dates**  \n",
        "   Missing end dates are assumed to represent ongoing relationships.  \n",
        "   Missing `end_year` values were filled with **2022**, which is outside the data range (2005–2021).\n",
        "\n",
        "4. **Create a pseudo-panel**  \n",
        "   Generated one observation (row) for **each year between `start_year` and `end_year`** for every relationship.\n",
        "\n",
        "5. **Filter relationship types**  \n",
        "   Retained only:\n",
        "   - `REL_TYPE = \"CUSTOMER\"`\n",
        "   - `REL_TYPE = \"SUPPLIER\"`\n",
        "\n",
        "6. **Invert relationships to capture all dyads**  \n",
        "   The dataset lists relationships from the focal firm’s perspective, but firms may also appear as customers or suppliers of other focal firms.  \n",
        "   To ensure all relationships are captured:\n",
        "   - Created a copy of the dataset\n",
        "   - Inverted key fields:\n",
        "     - `source_name`, `source_id`, `source_cusip` → `target_name`, `target_id`, `target_cusip`\n",
        "     - `REL_TYPE = \"CUSTOMER\"` → `\"SUPPLIER\"`\n",
        "     - `REL_TYPE = \"SUPPLIER\"` → `\"CUSTOMER\"`\n",
        "\n",
        "7. **Append datasets**  \n",
        "   Appended the original and inverted datasets.\n",
        "\n",
        "8. **Drop duplicates**\n",
        "\n",
        "9. **Retain only customer relationships**  \n",
        "   Kept only `REL_TYPE = \"CUSTOMER\"`.\n",
        "\n",
        "   **Example**\n",
        "\n",
        "   **Original Table**\n",
        "\n",
        "   | Source | Target | Relationship |\n",
        "   |-------:|-------:|-------------|\n",
        "   | X      | Y      | Customer    |\n",
        "   | X      | Z      | Supplier    |\n",
        "\n",
        "   **Inverted Table**\n",
        "\n",
        "   | Source | Target | Relationship |\n",
        "   |-------:|-------:|-------------|\n",
        "   | Y      | X      | Supplier    |\n",
        "   | Z      | X      | Customer    |\n",
        "\n",
        "   **Appended Table**\n",
        "\n",
        "   | Source | Target | Relationship |\n",
        "   |-------:|-------:|-------------|\n",
        "   | X      | Y      | Customer    |\n",
        "   | X      | Z      | Supplier    |\n",
        "   | Y      | X      | Supplier    |\n",
        "   | Z      | X      | Customer    |\n",
        "\n",
        "10. **Build directed graph**  \n",
        "    Constructed a directed graph where edges always go from:\n",
        "    - **Source = supplier**\n",
        "    - **Target = customer**\n",
        "\n",
        "    - **203,026 nodes**\n",
        "    - **749,168 edges**\n",
        "\n",
        "11. **Build one graph per year**\n",
        "\n",
        "12. **Compute node-level network measures (per year)**  \n",
        "    - Reciprocity  \n",
        "    - In-degree  \n",
        "    - Out-degree  \n",
        "    - In-degree centrality  \n",
        "    - Out-degree centrality  \n",
        "    - Degree centrality  \n",
        "    - Eigenvector centrality  \n",
        "    - Clustering coefficient  \n",
        "    - Core number  \n",
        "\n",
        "13. **Add firm identifier**  \n",
        "    Added the node’s (source company) **CUSIP** to the output table.\n",
        "\n",
        "14. **Export final dataset**  \n",
        "    Exported the resulting dataset as a `.dta` file.\n",
        "\n"
      ],
      "metadata": {
        "id": "dQr7EqdrNlrq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3Xs3l0J0wC8"
      },
      "outputs": [],
      "source": [
        "#import packages\n",
        "import pandas as pd\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/scl/fi/v25zqpcj2g9sfwr928fcs/seglink_withSIC_30Oct25.dta?rlkey=19q6hymbsf5osmxi8pdy1rkpj&dl=0"
      ],
      "metadata": {
        "id": "Uzg6BaxxN3la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##rename file to get rid of the weird extension name"
      ],
      "metadata": {
        "id": "Bxvx8ojtPR8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_stata(\"seglink_withSIC_30Oct25.dta?rlkey=19q6hymbsf5osmxi8pdy1rkpj\")"
      ],
      "metadata": {
        "id": "eZC1hxlON-F5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "AkhQRCwJPxbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create year column based on srcdate\n",
        "df[\"year\"] = df['srcdate'].dt.year"
      ],
      "metadata": {
        "id": "VcAAwHQnRMw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspect df\n",
        "df.columns"
      ],
      "metadata": {
        "id": "WJJqkDl_1Mkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create directed graph\n",
        "G = nx.from_pandas_edgelist(\n",
        "    df,\n",
        "    source=\"gvkey\",\n",
        "    target=\"cgvkey\",\n",
        "    edge_attr=[\"salecs\", \"year\"],\n",
        "    create_using=nx.DiGraph(),\n",
        ")"
      ],
      "metadata": {
        "id": "CGQCgSJLBNo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check number of nodes and edges\n",
        "print(f\"number of nodes: {len(G.nodes)}\")\n",
        "print(f\"number of edges: {len(G.edges)}\")"
      ],
      "metadata": {
        "id": "dmcbvLAECnZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearly_subgraphs = {}\n",
        "for year in range(2003, 2020):\n",
        "\n",
        "    # Create the directed graph from your dataframe (replace 'new_panel_df_Customer' with your actual dataframe)\n",
        "    yearly_subgraphs[year] = nx.from_pandas_edgelist(\n",
        "                              df[df['year']==year],\n",
        "                              source=\"gvkey\",\n",
        "                              target=\"cgvkey\",\n",
        "                              edge_attr=[\"SOURCE_it\", \"SOURCE_it_hdwr\", \"SOURCE_ict\", \"SOURCE_ict_hdwr\", \"year\"],\n",
        "                              create_using=nx.DiGraph(),\n",
        "                          )\n",
        "\n",
        "    #Create year attribute\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], year, name=f'year')\n",
        "\n",
        "    # Reciprocity\n",
        "    reciprocity_values = {node: nx.reciprocity(yearly_subgraphs[year], node) for node in yearly_subgraphs[year].nodes()}\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], reciprocity_values, name=f'reciprocity')\n",
        "\n",
        "    # Compute in-degree and out-degree as dictionaries {node: degree}\n",
        "    in_degree_values = dict(yearly_subgraphs[year].in_degree())\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], in_degree_values, name='in_degree')\n",
        "\n",
        "    # Set only the degree value (not the full list of tuples)\n",
        "    out_degree_values = dict(yearly_subgraphs[year].out_degree())\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], out_degree_values, name='out_degree')\n",
        "\n",
        "\n",
        "    # Compute in-degree and out-degree if SOURCE_IT == 1\n",
        "    edges_it = [(u, v) for u, v, d in yearly_subgraphs[year].edges(data=True) if d.get('SOURCE_it') == 1]\n",
        "    subgraph_it = yearly_subgraphs[year].edge_subgraph(edges_it).copy()\n",
        "    in_degree_values_it = dict(subgraph_it.in_degree(weight=None))\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], in_degree_values_it, name=f'in_degree_it')\n",
        "    out_degree_values_it = dict(subgraph_it.out_degree(weight=None))\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], out_degree_values_it, name=f'out_degree_it')\n",
        "    print(f\"In and Out Degree Source IT for {year} calculated.\")\n",
        "\n",
        "    # Compute in-degree and out-degree if SOURCE_IT_HDWR == 1\n",
        "    edges_it_hdwr = [(u, v) for u, v, d in yearly_subgraphs[year].edges(data=True) if d.get('SOURCE_it_hdwr') == 1]\n",
        "    subgraph_it_hdwr = yearly_subgraphs[year].edge_subgraph(edges_it_hdwr).copy()\n",
        "    in_degree_values_it_hdwr = dict(subgraph_it_hdwr.in_degree(weight=None))\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], in_degree_values_it_hdwr, name=f'in_degree_it_hdwr')\n",
        "\n",
        "    out_degree_values_it_hdwr = dict(subgraph_it_hdwr.out_degree(weight=None))\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], out_degree_values_it_hdwr, name=f'out_degree_it_hdwr')\n",
        "    print(f\"In and Out Degree Source IT HDWR for {year} calculated.\")\n",
        "\n",
        "    # Compute in-degree and out-degree if SOURCE_ICT == 1\n",
        "    edges_ict = [(u, v) for u, v, d in yearly_subgraphs[year].edges(data=True) if d.get('SOURCE_ict') == 1]\n",
        "    subgraph_ict = yearly_subgraphs[year].edge_subgraph(edges_ict).copy()\n",
        "    in_degree_values_ict = dict(subgraph_ict.in_degree(weight=None))\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], in_degree_values_ict, name=f'in_degree_ict')\n",
        "\n",
        "    out_degree_values_ict = dict(subgraph_ict.out_degree(weight=None))\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], out_degree_values_ict, name=f'out_degree_ict')\n",
        "    print(f\"In and Out Degree Source ICT for {year} calculated.\")\n",
        "\n",
        "    # # Compute in-degree and out-degree if TARGET_ICT_HDWR == 1\n",
        "    edges_ict_hdwr = [(u, v) for u, v, d in yearly_subgraphs[year].edges(data=True) if d.get('SOURCE_ict_hdwr') == 1]\n",
        "    subgraph_ict_hdwr = yearly_subgraphs[year].edge_subgraph(edges_ict_hdwr).copy()\n",
        "    in_degree_values_ict_hdwr = dict(subgraph_ict_hdwr.in_degree(weight=None))\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], in_degree_values_ict_hdwr, name=f'in_degree_ict_hdwr')\n",
        "\n",
        "    out_degree_values_ict_hdwr = dict(subgraph_ict_hdwr.out_degree(weight=None))\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], out_degree_values_ict_hdwr, name=f'out_degree_ict_hdwr')\n",
        "    print(f\"In and Out Degree Source IT HDWR for {year} calculated.\")\n",
        "\n",
        "\n",
        "    # In-degree and Out-degree Centrality\n",
        "    in_degree_centrality_values = nx.in_degree_centrality(yearly_subgraphs[year])\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], in_degree_centrality_values, name=f'in_degree_centrality')\n",
        "\n",
        "    out_degree_centrality_values = nx.out_degree_centrality(yearly_subgraphs[year])\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], out_degree_centrality_values, name=f'out_degree_centrality')\n",
        "\n",
        "    # Betweenness Centrality\n",
        "    betweenness_centrality_values = nx.betweenness_centrality(yearly_subgraphs[year], seed=17)\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], betweenness_centrality_values, name=f'betweenness_centrality')\n",
        "\n",
        "    # Closeness Centrality\n",
        "    closeness_centrality_values = nx.closeness_centrality(yearly_subgraphs[year])\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], closeness_centrality_values, name=f'closeness_centrality')\n",
        "\n",
        "    # Eigenvector Centrality\n",
        "    try:\n",
        "        eigenvector_centrality_values = nx.eigenvector_centrality(yearly_subgraphs[year], max_iter=1000)\n",
        "    except nx.PowerIterationFailedConvergence:\n",
        "        # Handle case where eigenvector centrality fails to converge\n",
        "        eigenvector_centrality_values = {node: float('nan') for node in yearly_subgraphs[year].nodes()}\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], eigenvector_centrality_values, name=f'eigenvector_centrality')\n",
        "\n",
        "    # PageRank\n",
        "    pagerank_values = nx.pagerank(yearly_subgraphs[year])\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], pagerank_values, name=f'pagerank')\n",
        "\n",
        "    # Clustering Coefficient\n",
        "    clustering_coefficient_values = nx.clustering(yearly_subgraphs[year])\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], clustering_coefficient_values, name=f'clustering_coefficient')\n",
        "\n",
        "\n",
        "    # Assortativity (for directed degree distributions)\n",
        "    try:\n",
        "        assortativity_coefficient = nx.degree_pearson_correlation_coefficient(yearly_subgraphs[year])\n",
        "    except nx.NetworkXError:\n",
        "        # Handle the case where assortativity cannot be calculated\n",
        "        assortativity_coefficient = float('nan')  # Assign NaN if calculation fails\n",
        "\n",
        "    # Set it for all nodes to keep consistent structure\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], {n: assortativity_coefficient for n in yearly_subgraphs[year].nodes()}, name=f'assortativity_coefficient')\n",
        "\n",
        "    # # Information_centrality (only available for undirected graphs)\n",
        "    # information_centrality_values = nx.information_centrality(yearly_subgraphs[year])\n",
        "    # nx.set_node_attributes(yearly_subgraphs[year], information_centrality_values, name=f'information_centrality')\n",
        "\n",
        "    # degree_centrality\n",
        "    degree_centrality_values = nx.degree_centrality(yearly_subgraphs[year])\n",
        "    nx.set_node_attributes(yearly_subgraphs[year], degree_centrality_values, name=f'degree_centrality')\n",
        "\n",
        "    print(f\"Metrics for year {year} calculated and added to graph.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Now gather all the nodes and their attributes into a long format\n",
        "\n",
        "# Define the column names\n",
        "columns = ['node', 'year', 'reciprocity', 'in_degree', 'out_degree',\n",
        "           'in_degree_it', 'out_degree_it',\n",
        "           'in_degree_it_hdwr', 'out_degree_it_hdwr',\n",
        "           'in_degree_centrality', 'out_degree_centrality',\n",
        "           'betweenness_centrality', 'closeness_centrality', 'eigenvector_centrality',\n",
        "           'pagerank', 'clustering_coefficient', 'assortativity_coefficient', 'degree_centrality']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9Gi7dd1YvEyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty DataFrame\n",
        "dfNet = pd.DataFrame(columns=columns)\n",
        "\n",
        "for year in range(2003, 2020):\n",
        "  # Step 1: Get nodes with their attributes (metadata)\n",
        "  node_data = yearly_subgraphs[year].nodes(data=True)\n",
        "\n",
        "  # Step 2: Convert nodes with metadata to a list of dictionaries\n",
        "  nodes_list = [{**{'node': n}, **d} for n, d in node_data]\n",
        "\n",
        "  # Step 3: Convert the list of dictionaries to a Pandas DataFrame\n",
        "  dfNet = pd.concat([dfNet, pd.DataFrame(nodes_list)], ignore_index=True)\n",
        "\n",
        "  #Enforce fields as numeric\n",
        "  dfNet.year = dfNet.year.astype(int)\n",
        "  dfNet.in_degree = dfNet.in_degree.astype(int)\n",
        "  dfNet.out_degree = dfNet.out_degree.astype(int)\n",
        "  dfNet.in_degree_it = dfNet.in_degree_it.astype('Int64')\n",
        "  dfNet.out_degree_it = dfNet.out_degree_it.astype('Int64')\n",
        "  dfNet.in_degree_it_hdwr = dfNet.in_degree_it_hdwr.astype('Int64')\n",
        "  dfNet.out_degree_it_hdwr = dfNet.out_degree_it_hdwr.astype('Int64')\n",
        "\n",
        "  #replace NAs with zero\n",
        "  dfNet.fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "0oDVDrqZL0rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add Cusip to the dataframe\n",
        "\n",
        "cusip = df[['gvkey',\t'scusip']].drop_duplicates().set_index('gvkey').to_dict()['scusip']\n",
        "dfNet['cusip'] = dfNet['node'].map(cusip)\n"
      ],
      "metadata": {
        "id": "1rMkfWqk4ge1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfNet['in_degree'] = pd.to_numeric(dfNet['in_degree'], errors='coerce')\n",
        "dfNet['out_degree'] = pd.to_numeric(dfNet['out_degree'], errors='coerce')"
      ],
      "metadata": {
        "id": "9PSYmI0QLRDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfNet.year = dfNet.year.astype(int)\n",
        "dfNet['node'] = dfNet['node'].astype(str)\n",
        "dfNet.to_stata('/content/drive/MyDrive/FactsetSupplyChainNetwork/networkMeasuresWRDS_SIC_2003_2019_30Oct25v1aos.dta')"
      ],
      "metadata": {
        "id": "M9sznKUf4gVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###End of Data Modelling.\n",
        "###Begin Data Exploration and Small Supply Network Visualization"
      ],
      "metadata": {
        "id": "lrqATFgPtXCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Examples APPLE"
      ],
      "metadata": {
        "id": "yUlzRsd16apq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['gvkey']=='001690']"
      ],
      "metadata": {
        "id": "2PvEBxdH6am1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['cgvkey']=='001690']"
      ],
      "metadata": {
        "id": "jyWXBVn9eDXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfNet[dfNet['node']=='1690']"
      ],
      "metadata": {
        "id": "r7KsGV9teQhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_reciprocity = {node: nx.reciprocity(G, node) for node in G.nodes()}"
      ],
      "metadata": {
        "id": "P7dUpVmxgwqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(reciprocity_values.values(), bins=20)\n",
        "plt.xlabel('Reciprocity Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Reciprocity Values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y-A8pkNJhnhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_choice = df[(df['gvkey']=='287882') | (df['cgvkey']=='287882') | (df['gvkey']=='164046') | (df['cgvkey']=='164046') | (df['gvkey']=='278151') | (df['cgvkey']=='278151') | (df['gvkey']=='318221') | (df['cgvkey']=='318221')]"
      ],
      "metadata": {
        "id": "teDzxnGdybZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_choice"
      ],
      "metadata": {
        "id": "RMeGhae707Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pep_yearly_subgraphs = {}\n",
        "for year in range(2017, 2020):\n",
        "    # Create the directed graph from your dataframe (replace 'new_panel_df_Customer' with your actual dataframe)\n",
        "    pep_yearly_subgraphs[year] = nx.from_pandas_edgelist(\n",
        "                              df_choice[df_choice['year']==year],\n",
        "                              source=\"gvkey\",\n",
        "                              target=\"cgvkey\",\n",
        "                              edge_attr=[\"year\"],\n",
        "                              create_using=nx.DiGraph(),\n",
        "                          )"
      ],
      "metadata": {
        "id": "fb1wGXZHyWe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nx.draw(pep_yearly_subgraphs[2017], with_labels=True, node_color='lightblue', node_size=500)"
      ],
      "metadata": {
        "id": "NP7yjHetB8UJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nx.draw(pep_yearly_subgraphs[2018], with_labels=True, node_color='lightblue', node_size=500)"
      ],
      "metadata": {
        "id": "nDoK_lW_zeC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "nx.draw(pep_yearly_subgraphs[2019], with_labels=True, node_color='lightblue', node_size=500)"
      ],
      "metadata": {
        "id": "nI3kQLHFzhcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "G = pep_yearly_subgraphs[2018]\n",
        "\n",
        "# group nodes by column\n",
        "very_top = [\"009835\"]\n",
        "top_nodes = [\"164046\", \"278151\"]\n",
        "middle_nodes = [\"287882\", \"013971\"]\n",
        "bottom_nodes = [\"318221\"]\n",
        "options = {\n",
        "    \"font_size\": 12,\n",
        "    \"node_size\": 2500,\n",
        "    \"node_color\": \"white\",\n",
        "    \"edgecolors\": \"black\",\n",
        "    \"linewidths\": 1,\n",
        "    \"width\": 1,\n",
        "}\n",
        "\n",
        "# set the position according to column (x-coord)\n",
        "pos = {n: (i, 0) for i, n in enumerate(very_top)}\n",
        "pos.update({n: (i, -1) for i, n in enumerate(top_nodes)})\n",
        "pos.update({n: (i, -2) for i, n in enumerate(middle_nodes)})\n",
        "pos.update({n: (i, -3) for i, n in enumerate(bottom_nodes)})\n",
        "\n",
        "nx.draw_networkx(G, pos, **options)\n",
        "\n",
        "#highlight one node by changing the color of the line\n",
        "nx.draw_networkx_nodes(G, pos, nodelist=[\"287882\"], node_color=\"red\", node_size=2500)\n",
        "\n",
        "# Set margins for the axes so that nodes aren't clipped\n",
        "ax = plt.gca()\n",
        "ax.margins(0.1)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yJiMMfss5yGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from networkx.drawing.layout import spring_layout\n",
        "\n",
        "G = pep_yearly_subgraphs[2019]\n",
        "\n",
        "# group nodes by column\n",
        "very_top = [\"009835\"]\n",
        "top_nodes = [\"164046\", \"278151\"]\n",
        "middle_nodes = [\"287882\", \"013971\"]\n",
        "bottom_nodes = [\"318221\"]\n",
        "options = {\n",
        "    \"font_size\": 12,\n",
        "    \"node_size\": 2500,\n",
        "    \"node_color\": \"white\",\n",
        "    \"edgecolors\": \"black\",\n",
        "    \"linewidths\": 1,\n",
        "    \"width\": 1,\n",
        "}\n",
        "\n",
        "# set the position according to column (x-coord)\n",
        "\n",
        "pos = {n: (i, 0) for i, n in enumerate(very_top)}\n",
        "pos.update({n: (i, -1) for i, n in enumerate(top_nodes)})\n",
        "pos.update({n: (i, -2) for i, n in enumerate(middle_nodes)})\n",
        "pos.update({n: (i, -3) for i, n in enumerate(bottom_nodes)})\n",
        "\n",
        "nx.draw_networkx(G, pos, **options)\n",
        "\n",
        "#highlight one node by changing the color of the line\n",
        "nx.draw_networkx_nodes(G, pos, nodelist=[\"287882\"], node_color=\"red\", node_size=2500)\n",
        "\n",
        "# Set margins for the axes so that nodes aren't clipped\n",
        "ax = plt.gca()\n",
        "ax.margins(0.1)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KwQn_gWv3UpZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}